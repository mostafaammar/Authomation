{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Chapter4 project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuzDxtRBUGKnfAUWYl3+7I",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostafaammar/Authomation/blob/master/Copy_of_Chapter4_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phAij98f_CEJ"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsOHRhPh_WAo",
        "outputId": "3b02001b-eb03-4df8-f968-e66bc4272791"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "print('x_train =', x_train.shape)\n",
        "print('x_valid =', x_valid.shape)\n",
        "print('x_test =', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train = (45000, 32, 32, 3)\n",
            "x_valid = (5000, 32, 32, 3)\n",
            "x_test = (10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeNnDwZm_xgR"
      },
      "source": [
        "#normalize Data\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_valid = (x_valid-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        "#onehot encoding\n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_valid = np_utils.to_categorical(y_valid,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=15,\n",
        "width_shift_range=0.1,\n",
        "height_shift_range=0.1,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=False\n",
        ")\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr_JDJZPBzw3",
        "outputId": "324f5e6e-8725-4e71-a1df-1c58dccf4954"
      },
      "source": [
        "base_hidden_units = 32\n",
        "weight_decay = 1e-4\n",
        "model = Sequential()\n",
        "# CONV1\n",
        "model.add(Conv2D(base_hidden_units, kernel_size= 3, padding='same',\n",
        "kernel_regularizer=regularizers.l2(weight_decay),\n",
        "input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# CONV2\n",
        "model.add(Conv2D(base_hidden_units, kernel_size= 3, padding='same',\n",
        "kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "# CONV3\n",
        "model.add(Conv2D(base_hidden_units * 2, kernel_size= 3, padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# CONV4\n",
        "model.add(Conv2D(base_hidden_units * 2, kernel_size= 3, padding='same',\n",
        "kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "# CONV5\n",
        "model.add(Conv2D(base_hidden_units * 4, kernel_size= 3, padding='same',\n",
        "kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# CONV6\n",
        "model.add(Conv2D(base_hidden_units * 4, kernel_size= 3, padding='same',\n",
        "kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "# POOL + Dropout\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKfdBGbBCTdk",
        "outputId": "68a52ec9-427a-4a75-9760-5364c2af3984"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 125\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#print(Adam)\n",
        "#print(tf.optimizers.Adam)\n",
        "checkpointer = ModelCheckpoint(filepath='model.100epochs.hdf5', verbose=1, save_best_only=True )\n",
        "optimizer = Adam(lr=0.0001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=batch_size), callbacks=[checkpointer],steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,verbose=2, validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "351/351 - 63s - loss: 2.8236 - accuracy: 0.2623 - val_loss: 2.0304 - val_accuracy: 0.2614\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.03044, saving model to model.100epochs.hdf5\n",
            "Epoch 2/125\n",
            "351/351 - 30s - loss: 2.1076 - accuracy: 0.3498 - val_loss: 1.5520 - val_accuracy: 0.4762\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.03044 to 1.55195, saving model to model.100epochs.hdf5\n",
            "Epoch 3/125\n",
            "351/351 - 30s - loss: 1.8711 - accuracy: 0.4021 - val_loss: 1.4472 - val_accuracy: 0.5096\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.55195 to 1.44718, saving model to model.100epochs.hdf5\n",
            "Epoch 4/125\n",
            "351/351 - 30s - loss: 1.7299 - accuracy: 0.4370 - val_loss: 1.3965 - val_accuracy: 0.5224\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.44718 to 1.39651, saving model to model.100epochs.hdf5\n",
            "Epoch 5/125\n",
            "351/351 - 30s - loss: 1.6417 - accuracy: 0.4643 - val_loss: 1.3183 - val_accuracy: 0.5498\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.39651 to 1.31832, saving model to model.100epochs.hdf5\n",
            "Epoch 6/125\n",
            "351/351 - 30s - loss: 1.5659 - accuracy: 0.4892 - val_loss: 1.3186 - val_accuracy: 0.5482\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.31832\n",
            "Epoch 7/125\n",
            "351/351 - 30s - loss: 1.4858 - accuracy: 0.5118 - val_loss: 1.2939 - val_accuracy: 0.5594\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.31832 to 1.29391, saving model to model.100epochs.hdf5\n",
            "Epoch 8/125\n",
            "351/351 - 31s - loss: 1.4265 - accuracy: 0.5333 - val_loss: 1.2585 - val_accuracy: 0.5648\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.29391 to 1.25845, saving model to model.100epochs.hdf5\n",
            "Epoch 9/125\n",
            "351/351 - 30s - loss: 1.3625 - accuracy: 0.5533 - val_loss: 1.2252 - val_accuracy: 0.5852\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.25845 to 1.22523, saving model to model.100epochs.hdf5\n",
            "Epoch 10/125\n",
            "351/351 - 30s - loss: 1.3004 - accuracy: 0.5715 - val_loss: 1.1269 - val_accuracy: 0.6150\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.22523 to 1.12687, saving model to model.100epochs.hdf5\n",
            "Epoch 11/125\n",
            "351/351 - 30s - loss: 1.2612 - accuracy: 0.5853 - val_loss: 1.1480 - val_accuracy: 0.6092\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.12687\n",
            "Epoch 12/125\n",
            "351/351 - 30s - loss: 1.2260 - accuracy: 0.5980 - val_loss: 1.1089 - val_accuracy: 0.6204\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.12687 to 1.10895, saving model to model.100epochs.hdf5\n",
            "Epoch 13/125\n",
            "351/351 - 30s - loss: 1.1844 - accuracy: 0.6099 - val_loss: 1.0824 - val_accuracy: 0.6380\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.10895 to 1.08237, saving model to model.100epochs.hdf5\n",
            "Epoch 14/125\n",
            "351/351 - 30s - loss: 1.1502 - accuracy: 0.6170 - val_loss: 1.0843 - val_accuracy: 0.6304\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.08237\n",
            "Epoch 15/125\n",
            "351/351 - 30s - loss: 1.1142 - accuracy: 0.6328 - val_loss: 1.0023 - val_accuracy: 0.6648\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.08237 to 1.00228, saving model to model.100epochs.hdf5\n",
            "Epoch 16/125\n",
            "351/351 - 31s - loss: 1.0851 - accuracy: 0.6383 - val_loss: 0.9316 - val_accuracy: 0.6938\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.00228 to 0.93164, saving model to model.100epochs.hdf5\n",
            "Epoch 17/125\n",
            "351/351 - 30s - loss: 1.0524 - accuracy: 0.6472 - val_loss: 1.0042 - val_accuracy: 0.6638\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.93164\n",
            "Epoch 18/125\n",
            "351/351 - 30s - loss: 1.0209 - accuracy: 0.6590 - val_loss: 0.9324 - val_accuracy: 0.6884\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.93164\n",
            "Epoch 19/125\n",
            "351/351 - 31s - loss: 1.0000 - accuracy: 0.6691 - val_loss: 0.9161 - val_accuracy: 0.7018\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.93164 to 0.91612, saving model to model.100epochs.hdf5\n",
            "Epoch 20/125\n",
            "351/351 - 30s - loss: 0.9830 - accuracy: 0.6720 - val_loss: 0.9494 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.91612\n",
            "Epoch 21/125\n",
            "351/351 - 30s - loss: 0.9578 - accuracy: 0.6816 - val_loss: 0.9156 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.91612 to 0.91558, saving model to model.100epochs.hdf5\n",
            "Epoch 22/125\n",
            "351/351 - 30s - loss: 0.9386 - accuracy: 0.6889 - val_loss: 0.8569 - val_accuracy: 0.7178\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.91558 to 0.85693, saving model to model.100epochs.hdf5\n",
            "Epoch 23/125\n",
            "351/351 - 30s - loss: 0.9231 - accuracy: 0.6922 - val_loss: 0.8542 - val_accuracy: 0.7240\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.85693 to 0.85423, saving model to model.100epochs.hdf5\n",
            "Epoch 24/125\n",
            "351/351 - 30s - loss: 0.9010 - accuracy: 0.7009 - val_loss: 0.8156 - val_accuracy: 0.7408\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.85423 to 0.81565, saving model to model.100epochs.hdf5\n",
            "Epoch 25/125\n",
            "351/351 - 30s - loss: 0.8848 - accuracy: 0.7058 - val_loss: 0.8180 - val_accuracy: 0.7366\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.81565\n",
            "Epoch 26/125\n",
            "351/351 - 30s - loss: 0.8684 - accuracy: 0.7093 - val_loss: 0.8160 - val_accuracy: 0.7374\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.81565\n",
            "Epoch 27/125\n",
            "351/351 - 30s - loss: 0.8584 - accuracy: 0.7136 - val_loss: 0.8193 - val_accuracy: 0.7346\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.81565\n",
            "Epoch 28/125\n",
            "351/351 - 31s - loss: 0.8459 - accuracy: 0.7191 - val_loss: 0.7609 - val_accuracy: 0.7572\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.81565 to 0.76093, saving model to model.100epochs.hdf5\n",
            "Epoch 29/125\n",
            "351/351 - 30s - loss: 0.8349 - accuracy: 0.7209 - val_loss: 0.7776 - val_accuracy: 0.7522\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.76093\n",
            "Epoch 30/125\n",
            "351/351 - 31s - loss: 0.8213 - accuracy: 0.7276 - val_loss: 0.7406 - val_accuracy: 0.7628\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.76093 to 0.74059, saving model to model.100epochs.hdf5\n",
            "Epoch 31/125\n",
            "351/351 - 30s - loss: 0.8102 - accuracy: 0.7305 - val_loss: 0.7348 - val_accuracy: 0.7640\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.74059 to 0.73477, saving model to model.100epochs.hdf5\n",
            "Epoch 32/125\n",
            "351/351 - 30s - loss: 0.7969 - accuracy: 0.7346 - val_loss: 0.7292 - val_accuracy: 0.7668\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.73477 to 0.72918, saving model to model.100epochs.hdf5\n",
            "Epoch 33/125\n",
            "351/351 - 30s - loss: 0.7849 - accuracy: 0.7366 - val_loss: 0.7529 - val_accuracy: 0.7580\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.72918\n",
            "Epoch 34/125\n",
            "351/351 - 30s - loss: 0.7736 - accuracy: 0.7416 - val_loss: 0.7170 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.72918 to 0.71699, saving model to model.100epochs.hdf5\n",
            "Epoch 35/125\n",
            "351/351 - 30s - loss: 0.7581 - accuracy: 0.7470 - val_loss: 0.6934 - val_accuracy: 0.7792\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.71699 to 0.69336, saving model to model.100epochs.hdf5\n",
            "Epoch 36/125\n",
            "351/351 - 30s - loss: 0.7515 - accuracy: 0.7502 - val_loss: 0.7185 - val_accuracy: 0.7740\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.69336\n",
            "Epoch 37/125\n",
            "351/351 - 30s - loss: 0.7490 - accuracy: 0.7535 - val_loss: 0.6486 - val_accuracy: 0.7910\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.69336 to 0.64863, saving model to model.100epochs.hdf5\n",
            "Epoch 38/125\n",
            "351/351 - 30s - loss: 0.7342 - accuracy: 0.7580 - val_loss: 0.6843 - val_accuracy: 0.7834\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.64863\n",
            "Epoch 39/125\n",
            "351/351 - 30s - loss: 0.7302 - accuracy: 0.7588 - val_loss: 0.7002 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.64863\n",
            "Epoch 40/125\n",
            "351/351 - 30s - loss: 0.7182 - accuracy: 0.7606 - val_loss: 0.6766 - val_accuracy: 0.7836\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.64863\n",
            "Epoch 41/125\n",
            "351/351 - 30s - loss: 0.7110 - accuracy: 0.7665 - val_loss: 0.6661 - val_accuracy: 0.7860\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.64863\n",
            "Epoch 42/125\n",
            "351/351 - 30s - loss: 0.7028 - accuracy: 0.7680 - val_loss: 0.6462 - val_accuracy: 0.7918\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.64863 to 0.64616, saving model to model.100epochs.hdf5\n",
            "Epoch 43/125\n",
            "351/351 - 30s - loss: 0.6947 - accuracy: 0.7686 - val_loss: 0.6218 - val_accuracy: 0.8014\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.64616 to 0.62181, saving model to model.100epochs.hdf5\n",
            "Epoch 44/125\n",
            "351/351 - 30s - loss: 0.6929 - accuracy: 0.7701 - val_loss: 0.6140 - val_accuracy: 0.8024\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.62181 to 0.61404, saving model to model.100epochs.hdf5\n",
            "Epoch 45/125\n",
            "351/351 - 30s - loss: 0.6818 - accuracy: 0.7755 - val_loss: 0.6218 - val_accuracy: 0.8002\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.61404\n",
            "Epoch 46/125\n",
            "351/351 - 30s - loss: 0.6748 - accuracy: 0.7780 - val_loss: 0.6201 - val_accuracy: 0.8022\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.61404\n",
            "Epoch 47/125\n",
            "351/351 - 30s - loss: 0.6671 - accuracy: 0.7796 - val_loss: 0.6213 - val_accuracy: 0.8040\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.61404\n",
            "Epoch 48/125\n",
            "351/351 - 30s - loss: 0.6648 - accuracy: 0.7813 - val_loss: 0.6010 - val_accuracy: 0.8090\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.61404 to 0.60096, saving model to model.100epochs.hdf5\n",
            "Epoch 49/125\n",
            "351/351 - 30s - loss: 0.6598 - accuracy: 0.7831 - val_loss: 0.5923 - val_accuracy: 0.8126\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.60096 to 0.59228, saving model to model.100epochs.hdf5\n",
            "Epoch 50/125\n",
            "351/351 - 30s - loss: 0.6504 - accuracy: 0.7881 - val_loss: 0.5982 - val_accuracy: 0.8094\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.59228\n",
            "Epoch 51/125\n",
            "351/351 - 30s - loss: 0.6438 - accuracy: 0.7873 - val_loss: 0.5992 - val_accuracy: 0.8112\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.59228\n",
            "Epoch 52/125\n",
            "351/351 - 30s - loss: 0.6405 - accuracy: 0.7897 - val_loss: 0.6007 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.59228\n",
            "Epoch 53/125\n"
          ]
        }
      ]
    }
  ]
}